{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jax federated learning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RPo1Cw2p83pb",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow tensorflow-datasets tensorflow-federated\n",
        "!pip install -q jax dm-haiku"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRDenD5M0rDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Any, Generator, Tuple, Mapping, Sequence, Optional, Callable\n",
        "from collections import namedtuple\n",
        "import functools, inspect, time\n",
        "\n",
        "from absl import app\n",
        "import haiku as hk\n",
        "import jax\n",
        "from jax.experimental import optix\n",
        "from jax.tree_util import tree_multimap, tree_map, tree_reduce\n",
        "import jax.numpy as jnp\n",
        "from jax.lax import fori_loop\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_federated as tff\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S-RWB9G48uJA",
        "colab": {}
      },
      "source": [
        "Batch = Mapping[str, jnp.ndarray]\n",
        "ClientData = Generator[Batch, None, None]\n",
        "LossFunction = Callable[[hk.Params, Batch], jnp.ndarray]\n",
        "OptState = Any\n",
        "\n",
        "\n",
        "# define hyperparameters format.\n",
        "ServerHyperParams = namedtuple(\"ServerHyperParams\", \"sampled_clients\\\n",
        "                                                     batch_size\\\n",
        "                                                     num_epochs\\\n",
        "                                                     num_rounds\\\n",
        "                                                     seed\")\n",
        "\n",
        "# message to the client from server.\n",
        "ClientMessage = namedtuple(\"ClientMessage\", \"params\\\n",
        "                                             opt_init_input\")\n",
        "\n",
        "# message to the server from client.\n",
        "ServerMessage = namedtuple(\"ServerMessage\", \"aggregator_input\\\n",
        "                                             stateupdater_input\")\n",
        "\n",
        "\n",
        "# message to the server from client for book keeping.\n",
        "DiagnosticsMessage = namedtuple(\"DiagnosticsMessage\", \"train_loss\\\n",
        "                                                       train_acc\\\n",
        "                                                       test_loss\\\n",
        "                                                       test_acc\\\n",
        "                                                       weight\")\n",
        "ClientOutput = Tuple[ServerMessage, DiagnosticsMessage]\n",
        "\n",
        "# extracts messages from a list of client outputs.\n",
        "@jax.partial(jax.jit, static_argnums=[1])  # fix extractor.\n",
        "def extract_from_cout(\n",
        "    couts: Sequence[ClientOutput],\n",
        "    extractor: Callable[[ClientOutput], Any]\n",
        "    ) -> Sequence[Any]:\n",
        "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
        "  # TODO: use pytrees.transpose?\n",
        "  # msgs = fori_loop(0, len(couts),\n",
        "  #                    lambda i, msgs: msgs.append(extractor(couts[i])), [])\n",
        "  msgs = [extractor(cout) for cout in couts]\n",
        "  return msgs\n",
        "\n",
        "# Construct data for multiple clients.\n",
        "def make_federated_data(\n",
        "    client_data: tff.simulation.ClientData, \n",
        "    client_ids: Sequence[str],\n",
        "    batch_size : Optional[int] = 1024,\n",
        "    train : Optional[bool] = True,\n",
        "    num_epochs : Optional[int] = 1,\n",
        "      seed : Optional[int] = 0\n",
        "    ) -> Sequence[ClientData]:\n",
        "\n",
        "  # Construct a tf.data.Dataset for client.\n",
        "  def preprocess(\n",
        "      ds: tf.data.Dataset,\n",
        "      batch_size,\n",
        "      train,\n",
        "      num_epochs,\n",
        "      seed\n",
        "      ) -> ClientData:\n",
        "    \n",
        "    if train:\n",
        "      ds = ds.repeat(num_epochs).shuffle(10*batch_size, seed)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return tfds.as_numpy(ds)\n",
        "    \n",
        "  return [\n",
        "      preprocess(\n",
        "          client_data.create_tf_dataset_for_client(idx),\n",
        "          batch_size, train, num_epochs, seed)\n",
        "      for idx in client_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbTmc5DwjoON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Neural network model.\n",
        "def net_fn(batch: Batch) -> jnp.ndarray:\n",
        "  \"\"\"Standard LeNet-300-100 MLP network.\"\"\"\n",
        "  x = batch[\"pixels\"].astype(jnp.float32) / 255.\n",
        "  mlp = hk.Sequential([\n",
        "      hk.Flatten(),\n",
        "      hk.Linear(300), jax.nn.relu,\n",
        "      hk.Linear(100), jax.nn.relu,\n",
        "      hk.Linear(10), jax.nn.log_softmax])\n",
        "  return mlp(x)\n",
        "net: hk.Transformed = hk.transform(net_fn)\n",
        "  \n",
        "# Initialize neural network parameters \n",
        "def init(rng: jax.random.PRNGKey, batch: Batch) -> hk.Params:\n",
        "  return net.init(rng, batch)\n",
        "\n",
        "# get predictions from model.\n",
        "def forward(params: hk.Params, batch: Batch):\n",
        "  return jax.jit(net.apply)(params, batch)\n",
        "\n",
        "\n",
        "# Training loss (cross-entropy).\n",
        "@jax.jit\n",
        "def loss(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
        "  \"\"\"Compute the loss of the network, including L2.\"\"\"\n",
        "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
        "  preds = forward(params, batch)\n",
        "  labels = hk.one_hot(batch[\"label\"], 10)\n",
        "  # TODO: Put weight decay into optimizer\n",
        "  l2_loss = 0.5 * sum(jnp.sum(jnp.square(p)) for p in jax.tree_leaves(params))\n",
        "  softmax_xent = -jnp.mean(labels * preds)\n",
        "  return softmax_xent + 1e-4 * l2_loss\n",
        "\n",
        "# Evaluation metric (classification accuracy).\n",
        "@jax.jit\n",
        "def accuracy(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
        "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
        "  preds = forward(params, batch)\n",
        "  pred_class = jnp.argmax(preds, axis=-1)\n",
        "  return jnp.mean(pred_class == batch[\"label\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elJQ6h8MVeH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one local update step.\n",
        "@jax.partial(jax.jit, static_argnums=[2,4])  # fix loss function and optimizer.\n",
        "def run_one_step(\n",
        "    params: hk.Params,\n",
        "    batch: Batch,\n",
        "    client_opt: optix.InitUpdate,\n",
        "    opt_state: OptState,\n",
        "    loss: LossFunction\n",
        "    ) -> Tuple[hk.Params, OptState]:\n",
        "  \"\"\"Learning rule (stochastic gradient descent).\"\"\"\n",
        "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
        "  grads = jax.grad(loss)(params, batch)\n",
        "  updates, opt_state = client_opt.update(grads, opt_state)\n",
        "  new_params = optix.apply_updates(params, updates)\n",
        "  return new_params, opt_state  \n",
        "\n",
        "# perform client updates.\n",
        "def client_updater(\n",
        "    msg: ClientMessage,\n",
        "    ds: ClientData,\n",
        "    client_opt: optix.InitUpdate,\n",
        "    loss: LossFunction\n",
        "    ) -> ClientOutput:\n",
        "  opt_state = client_opt.init(*msg.opt_init_input)\n",
        "  # iterate through data making updates.\n",
        "  new_params = msg.params\n",
        "  for minibatch in ds:\n",
        "    new_params, opt_state = run_one_step(new_params, minibatch,\n",
        "                                     client_opt, \n",
        "                                     opt_state, \n",
        "                                     loss)\n",
        "  # compute and return the change in parameters.\n",
        "  params_update = tree_multimap(lambda x, y: x - y, new_params, msg.params)\n",
        "  \n",
        "  # TODO: replace with an function which constructs message  \n",
        "  msg_to_server = ServerMessage(\n",
        "      aggregator_input=params_update,\n",
        "      stateupdater_input=None\n",
        "  )\n",
        "\n",
        "  diagnostic_msg = DiagnosticsMessage(\n",
        "      train_loss=0,\n",
        "      train_acc=1,\n",
        "      test_loss=0,\n",
        "      test_acc=1,\n",
        "      weight=1\n",
        "  )\n",
        "  return msg_to_server, diagnostic_msg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBd1gWJMoA4K",
        "colab_type": "code",
        "outputId": "df8db9ef-ee4b-4097-9689-22ddbe82fdc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n",
        "example_train = make_federated_data(emnist_train, \n",
        "                                    emnist_train.client_ids[:3], \n",
        "                                    batch_size = 32,\n",
        "                                    num_epochs = 1,\n",
        "                                    seed = 0)\n",
        "\n",
        "# # Testing our client updater.\n",
        "# params = init(jax.random.PRNGKey(42), next(example_train[0]))\n",
        "# cmsg = ClientMessage(params, [params])\n",
        "# new_params = client_updater(\n",
        "#                 cmsg,\n",
        "#                 example_train[1],\n",
        "#                 optix.sgd(0.1),\n",
        "#                 loss\n",
        "#                 );"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:63: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
            "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJPMeGdIVAYd",
        "colab_type": "code",
        "outputId": "a1d030bc-2f40-4f20-adfb-f3925a651a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "emnist_train.client_ids == emnist_test.client_ids"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvRbtDM1wS_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# aggregate client updates.\n",
        "# TODO: make the aggregator stateful.\n",
        "@jax.jit\n",
        "def average_params(params_list: Sequence[hk.Params]) -> hk.Params: \n",
        "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
        "  num_params = len(params_list)\n",
        "  params_sum = functools.reduce(\n",
        "      lambda t1, t2: tree_multimap(sum, t1, t2), params_list)\n",
        "  params_avg = tree_map(lambda x: x/num_params, params_sum)\n",
        "  return params_avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9V22gJC2DIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# aggregate diagnositcs.\n",
        "@jax.jit\n",
        "def agg_diagnostics(\n",
        "    client_outputs: Sequence[ClientOutput]) -> DiagnosticsMessage:\n",
        "  d_msgs = extract_from_cout(client_outputs, lambda cout: cout[1])\n",
        "  # TODO: aggregate and report statistics\n",
        "  return d_msgs[0]\n",
        "\n",
        "\n",
        "# update server params.\n",
        "@jax.partial(jax.jit, static_argnums=[2,4])  # fix optimizer and aggregator.\n",
        "def server_updater(\n",
        "    server_params: hk.Params,\n",
        "    client_outputs: Sequence[ClientOutput],\n",
        "    server_opt: optix.InitUpdate,\n",
        "    opt_state: OptState,\n",
        "    aggregator: Callable[[Sequence[Any]], hk.Params]\n",
        "    ) -> Tuple[hk.Params, OptState]:\n",
        "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
        "  agg_inputs = extract_from_cout(client_outputs,\n",
        "                                 lambda cout: cout[0].aggregator_input)\n",
        "  agg_update = aggregator(agg_inputs)\n",
        "  eff_grads = tree_map(lambda x: -1.0*x, agg_update)  # effective gradient.\n",
        "  updates, opt_state = server_opt.update(eff_grads, opt_state)\n",
        "  # TODO: allow opt_state to also be explicitly updated by state_updater\n",
        "  server_params = optix.apply_updates(server_params, updates)\n",
        "  return server_params, opt_state\n",
        "\n",
        "# one round of federated learning.\n",
        "def run_one_round(\n",
        "    server_params: hk.Params,\n",
        "    hyperparams: ServerHyperParams,\n",
        "    client_data: tff.simulation.ClientData,\n",
        "    client_opt: optix.InitUpdate,\n",
        "    server_opt: optix.InitUpdate,\n",
        "    opt_state: OptState,\n",
        "    aggregator: Callable[[Sequence[Any]], hk.Params],\n",
        "    loss: LossFunction,\n",
        "    rng: jax.random.PRNGKey\n",
        ") -> Tuple[hk.Params, OptState]:\n",
        "\n",
        "  # choose `num_sample` indices out of `num_total` clients.\n",
        "  num_total = len(client_data.client_ids)\n",
        "  clientid_indx = jax.random.shuffle(\n",
        "      rng, jnp.arange(num_total))[:hyperparams.sampled_clients]\n",
        "  active_client_ids = [client_data.client_ids[i] for i in clientid_indx]\n",
        "\n",
        "  print(\"making datasets for sampled clients.\")\n",
        "  sampled_dss = make_federated_data(client_data, active_client_ids, \n",
        "                            hyperparams.batch_size,\n",
        "                            True,\n",
        "                            hyperparams.num_epochs,\n",
        "                            hyperparams.seed)\n",
        "  \n",
        "  print(\"computing updates from active clients.\")\n",
        "  # TODO: replace with an function which constructs message\n",
        "  msg_to_clients = ClientMessage(\n",
        "      params=server_params, \n",
        "      opt_init_input=[server_params])\n",
        "  \n",
        "  client_outputs = list(map(lambda ds: client_updater(\n",
        "                          msg_to_clients,\n",
        "                          ds,\n",
        "                          client_opt,\n",
        "                          loss), sampled_dss))\n",
        "  print(\"aggregating client updates.\")\n",
        "  server_params, opt_state = server_updater(\n",
        "      server_params,\n",
        "      client_outputs,      \n",
        "      server_opt,      \n",
        "      opt_state,      \n",
        "      aggregator)\n",
        "  \n",
        "  # TODO: aggregate and incporate new diagnostics. needs state!\n",
        "  diag_state = agg_diagnostics(client_outputs)\n",
        "  \n",
        "  return server_params, opt_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuZcD4dEdzF3",
        "colab_type": "code",
        "outputId": "08edffde-2229-4389-e8b7-bcd7c00320e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "# Testing one round of federated averaging.\n",
        "params = init(jax.random.PRNGKey(42), next(example_train[0]))\n",
        "client_opt = optix.sgd(0.1)\n",
        "server_opt = optix.sgd(1.0)\n",
        "opt_state = server_opt.init(params)\n",
        "rng = jax.random.PRNGKey(0)\n",
        "hyperparams = ServerHyperParams(\n",
        "    sampled_clients = 3,\n",
        "    batch_size = 32,\n",
        "    num_epochs = 5,\n",
        "    num_rounds = 3,\n",
        "    seed = 7\n",
        ")\n",
        "\n",
        "run_one_round(\n",
        "    params,\n",
        "    hyperparams,\n",
        "    emnist_train,\n",
        "    client_opt,\n",
        "    server_opt,\n",
        "    opt_state,\n",
        "    average_params,\n",
        "    loss,\n",
        "    rng\n",
        ");"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/jax/lib/xla_bridge.py:123: UserWarning: No GPU/TPU found, falling back to CPU.\n",
            "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "making datasets for sampled clients.\n",
            "computing updates from active clients.\n",
            "compiling: run_one_step\n",
            "compiling: loss\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:63: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
            "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "compiling: run_one_step\n",
            "compiling: loss\n",
            "compiling: run_one_step\n",
            "compiling: loss\n",
            "compiling: run_one_step\n",
            "compiling: loss\n",
            "aggregating client updates.\n",
            "compiling: server_updater\n",
            "compiling: extract_from_cout\n",
            "compiling: average_params\n",
            "compiling: extract_from_cout\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsHof54fApTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def federated_learning(\n",
        "    hyperparams: ServerHyperParams,\n",
        "    client_data: tff.simulation.ClientData,\n",
        "    client_opt: optix.InitUpdate,\n",
        "    server_opt: optix.InitUpdate,\n",
        "    aggregator: Callable[[Sequence[hk.Params]], hk.Params],\n",
        "    loss: LossFunction,\n",
        "    init\n",
        "    ) -> hk.Params:\n",
        "  # initialize random generator, params, opt_state.\n",
        "  rng = jax.random.PRNGKey(hyperparams.seed)\n",
        "  # TODO: use synthethic data for init\n",
        "  server_params = init(rng, next(example_train[2]))\n",
        "  opt_state = server_opt.init(server_params)\n",
        "  rngs = jax.random.split(rng, hyperparams.num_rounds)\n",
        "  for round_num, rng in enumerate(rngs):\n",
        "    print(\"\\nrunning round {}\".format(round_num))\n",
        "    server_params, opt_state = run_one_round(server_params, hyperparams, \n",
        "                                             client_data, client_opt, \n",
        "                                             server_opt, opt_state, \n",
        "                                             aggregator, loss, rng)\n",
        "  return server_params\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT-dXeovX2Fd",
        "colab_type": "code",
        "outputId": "57c040e3-f579-497a-bb96-d30bed2d2004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "# testing federated learning code.\n",
        "hyperparams = ServerHyperParams(\n",
        "    sampled_clients = 3,\n",
        "    batch_size = 32,\n",
        "    num_epochs = 100,\n",
        "    num_rounds = 3,\n",
        "    seed = 22\n",
        ")\n",
        "\n",
        "federated_learning(\n",
        "    hyperparams,\n",
        "    emnist_train,\n",
        "    optix.sgd(0.1),\n",
        "    optix.sgd(1.0),\n",
        "    average_params,\n",
        "    loss,\n",
        "    init\n",
        "    );"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "running round 0\n",
            "making datasets for sampled clients.\n",
            "computing updates from active clients.\n",
            "compiling: run_one_step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:63: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
            "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "compiling: run_one_step\n",
            "compiling: loss\n",
            "aggregating client updates.\n",
            "compiling: server_updater\n",
            "compiling: extract_from_cout\n",
            "\n",
            "running round 1\n",
            "making datasets for sampled clients.\n",
            "computing updates from active clients.\n",
            "compiling: run_one_step\n",
            "compiling: loss\n",
            "compiling: run_one_step\n",
            "compiling: loss\n",
            "compiling: run_one_step\n",
            "aggregating client updates.\n",
            "\n",
            "running round 2\n",
            "making datasets for sampled clients.\n",
            "computing updates from active clients.\n",
            "aggregating client updates.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaE23XWAxE2x",
        "colab_type": "text"
      },
      "source": [
        "# Questions\n",
        "\n",
        "1. Does the net.init also initialize the output layer based on batch size?"
      ]
    }
  ]
}