{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/deepmind/dm-haiku\n",
      "  Cloning https://github.com/deepmind/dm-haiku to /tmp/pip-req-build-4vc4nx34\n",
      "  Running command git clone -q https://github.com/deepmind/dm-haiku /tmp/pip-req-build-4vc4nx34\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.1 in /opt/anaconda3/lib/python3.7/site-packages (from dm-haiku==0.0.1b0) (0.9.0)\n",
      "Collecting numpy>=1.18.0 (from dm-haiku==0.0.1b0)\n",
      "  Using cached https://files.pythonhosted.org/packages/1f/df/7988fbbdc8c9b8efb575029498ad84b77e023a3e4623e85068823a102b1d/numpy-1.18.4-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /opt/anaconda3/lib/python3.7/site-packages (from dm-haiku==0.0.1b0) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: dm-tree>=0.1.1 in /home/grimberg/.local/lib/python3.7/site-packages (from dm-haiku==0.0.1b0) (0.1.5)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/anaconda3/lib/python3.7/site-packages (from dm-haiku==0.0.1b0) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: tabulate>=0.7.5 in /home/grimberg/.local/lib/python3.7/site-packages (from dm-haiku==0.0.1b0) (0.8.7)\n",
      "Building wheels for collected packages: dm-haiku\n",
      "  Building wheel for dm-haiku (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dm-haiku: filename=dm_haiku-0.0.1b0-cp37-none-any.whl size=216854 sha256=c10165a110d178c91251d0d55bb70d66d90cfcd4f666af93ccbc5230e3c64654\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ubg6r2ca/wheels/97/0f/e9/17f34e377f8d4060fa88a7e82bee5d8afbf7972384768a5499\n",
      "Successfully built dm-haiku\n",
      "\u001b[31mERROR: tensorflow-federated 0.13.1 has requirement numpy~=1.17.5, but you'll have numpy 1.18.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, dm-haiku\n",
      "  Found existing installation: numpy 1.17.5\n",
      "    Uninstalling numpy-1.17.5:\n",
      "      Successfully uninstalled numpy-1.17.5\n",
      "  Found existing installation: dm-haiku 0.0.1b0\n",
      "    Uninstalling dm-haiku-0.0.1b0:\n",
      "      Successfully uninstalled dm-haiku-0.0.1b0\n",
      "Successfully installed dm-haiku-0.0.1b0 numpy-1.18.4\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --user git+https://github.com/deepmind/dm-haiku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: numpy in /home/grimberg/.local/lib/python3.7/site-packages (1.18.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --user numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --user setGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NVMLError_GpuIsLost",
     "evalue": "GPU is lost",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNVMLError_GpuIsLost\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1b99699b8a20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msetGPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/setGPU.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgpustat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpustat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPUStatCollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mratios\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'memory.used'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'memory.total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gpustat/core.py\u001b[0m in \u001b[0;36mnew_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvmlDeviceGetHandleByIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mgpu_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gpu_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mgpu_stat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPUStat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pynvml.py\u001b[0m in \u001b[0;36mnvmlDeviceGetHandleByIndex\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nvmlGetFunctionPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nvmlDeviceGetHandleByIndex_v2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m     \u001b[0m_nvmlCheckReturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pynvml.py\u001b[0m in \u001b[0;36m_nvmlCheckReturn\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_nvmlCheckReturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNVML_SUCCESS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNVMLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNVMLError_GpuIsLost\u001b[0m: GPU is lost"
     ]
    }
   ],
   "source": [
    "import setGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRDenD5M0rDY"
   },
   "outputs": [],
   "source": [
    "from typing import Any, Generator, Tuple, Mapping, Sequence, Optional, Callable, Union, NamedTuple\n",
    "from collections import namedtuple\n",
    "import functools, inspect, time, random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from absl import app\n",
    "import haiku as hk\n",
    "import jax\n",
    "from jax.experimental import optix\n",
    "from jax.tree_util import tree_multimap, tree_map, tree_reduce, tree_leaves\n",
    "import jax.numpy as jnp\n",
    "from jax.lax import fori_loop\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import module.utils as utils\n",
    "from module.custom_types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-RWB9G48uJA"
   },
   "outputs": [],
   "source": [
    "# extracts messages from a list of client outputs.\n",
    "@jax.partial(jax.jit, static_argnums=[1])  # fix extractor.\n",
    "def extract_from_cout(\n",
    "    couts: Sequence[ClientOutput],\n",
    "    extractor: Callable[[ClientOutput], Any]\n",
    "    ) -> Sequence[Any]:\n",
    "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  # TODO: use pytrees.transpose?\n",
    "  # msgs = fori_loop(0, len(couts),\n",
    "  #                    lambda i, msgs: msgs.append(extractor(couts[i])), [])\n",
    "  msgs = [extractor(cout) for cout in couts]\n",
    "  return msgs\n",
    "\n",
    "def init_client_states(client_data: Sequence[tf.data.Dataset]) -> Sequence[ClientState]:\n",
    "  return [ClientState() for i in range(len(client_data))]\n",
    "\n",
    "def make_jax_batch(batch: Mapping[str, tf.Tensor]) -> Batch:\n",
    "    \"\"\"Transform a Mapping[str, tf.Tensor] (tensorflow batch)\n",
    "    into a Mapping[str, jnp.array] (jax-compatible batch).\"\"\"\n",
    "    jax_batch = {}\n",
    "    for key in batch:\n",
    "        jax_batch[key] = jnp.array(batch[key].numpy())\n",
    "    return jax_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dss(clients: Sequence[Tuple[np.ndarray, np.ndarray]],\n",
    "             hyperparams: ServerHyperParams,\n",
    "             requesting_client: int = 0,\n",
    "             test_ratio: float = 0.5\n",
    ") -> Tuple[DatasetSequence, tf.data.Dataset]:\n",
    "    \"\"\"Make batched `tf.data.Dataset`s based on the (X,y) tuples representing\n",
    "    each client's data. \n",
    "    \n",
    "    requesting_client: Index of the age group for which a test set is created.\n",
    "    The training set for the requesting client is placed at index 0 in the returned\n",
    "    DatasetSequence.\"\"\"\n",
    "    if requesting_client < 0 or requesting_client >= len(clients):\n",
    "        raise ValueError(\"Unexpected 'requesting_client' argument: \"\n",
    "                         \"Expecting a non-negative int lower than \"\n",
    "                         \"{}.\".format(len(clients)))\n",
    "    \n",
    "    dss, ds_test = [None], None\n",
    "    for i, (X,y) in enumerate(clients):\n",
    "        if i == requesting_client:\n",
    "            test_size = hyperparams.batch_size * (1 + int(y.shape[0] // hyperparams.batch_size * test_ratio))\n",
    "            ds_test = utils.make_ds(X[:test_size], y[:test_size], hyperparams.batch_size)\n",
    "            dss[0] = utils.make_ds(X[test_size:], y[test_size:], hyperparams.batch_size)\n",
    "        else:\n",
    "            dss.append( utils.make_ds(X, y, hyperparams.batch_size) )\n",
    "    \n",
    "    assert (ds_test is not None)\n",
    "    \n",
    "    return dss, ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams = ServerHyperParams(\n",
    "#     num_rounds = 30,\n",
    "#     max_batches_per_round = 3,\n",
    "#     max_epochs_per_round = 1,\n",
    "#     batch_size = 10,\n",
    "#     seed = 420\n",
    "# )\n",
    "# dss, ds_test = make_dss(split_by_age(*load_2017annie_predict_EVD()), hyperparams)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in ds_test:\n",
    "#     print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbTmc5DwjoON"
   },
   "outputs": [],
   "source": [
    "# Neural network model.\n",
    "def net_fn(batch: Batch) -> jnp.ndarray:\n",
    "  \"\"\"Logistic regression for 2-class classification.\"\"\"\n",
    "  x = batch[\"features\"]\n",
    "  logistic_reg = hk.Sequential([\n",
    "      hk.Flatten(),\n",
    "      hk.Linear(2, with_bias=True), jax.nn.log_softmax\n",
    "  ])\n",
    "  return logistic_reg(x)\n",
    "net: hk.Transformed = hk.transform(net_fn)\n",
    "\n",
    "# Initialize neural network parameters \n",
    "def init(rng: jax.random.PRNGKey, batch: Batch) -> hk.Params:\n",
    "  return net.init(rng, batch)\n",
    "\n",
    "# get predictions from model.\n",
    "def forward(params: hk.Params, batch: Batch):\n",
    "  return jax.jit(net.apply)(params, batch)\n",
    "\n",
    "\n",
    "# Training loss (cross-entropy).\n",
    "@jax.jit\n",
    "def loss(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
    "  \"\"\"Compute the loss of the network, including L2.\"\"\"\n",
    "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  preds = forward(params, batch)\n",
    "  labels = hk.one_hot(batch[\"label\"], 2)\n",
    "  # TODO: Put weight decay into optimizer\n",
    "  l2_loss = 0.5 * sum(jnp.sum(jnp.square(p)) for p in jax.tree_leaves(params))\n",
    "  softmax_xent = -jnp.mean(labels * preds)\n",
    "  return softmax_xent + 1e-4 * l2_loss\n",
    "\n",
    "# Evaluation metric (classification accuracy).\n",
    "@jax.jit\n",
    "def accuracy(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
    "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  preds = forward(params, batch)\n",
    "  pred_class = jnp.argmax(preds, axis=-1)\n",
    "  return jnp.mean(pred_class == batch[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elJQ6h8MVeH6"
   },
   "outputs": [],
   "source": [
    "# one local update step.\n",
    "@jax.partial(jax.jit, static_argnums=[2,4])  # fix loss function and optimizer.\n",
    "def run_one_step(\n",
    "    params: hk.Params,\n",
    "    batch: Batch,\n",
    "    client_opt: optix.InitUpdate,\n",
    "    opt_state: OptState,\n",
    "    loss: LossFunction\n",
    "    ) -> Tuple[hk.Params, OptState]:\n",
    "  \"\"\"Learning rule (stochastic gradient descent).\"\"\"\n",
    "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  grads = jax.grad(loss)(params, batch)\n",
    "  updates, opt_state = client_opt.update(grads, opt_state)\n",
    "  new_params = optix.apply_updates(params, updates)\n",
    "  return new_params, opt_state  \n",
    "\n",
    "# perform client updates.\n",
    "def client_updater(\n",
    "    msg: ClientMessage,\n",
    "    ds: Sequence[Batch],\n",
    "    client_opt: optix.InitUpdate,\n",
    "    loss: LossFunction\n",
    "    ) -> ClientOutput:\n",
    "  opt_state = client_opt.init(*msg.opt_init_input)\n",
    "  # iterate through data making updates.\n",
    "  new_params = msg.params\n",
    "  train_loss, train_acc = [], []\n",
    "  for minibatch in ds:\n",
    "    new_params, opt_state = run_one_step(new_params,\n",
    "                                         minibatch,\n",
    "                                         client_opt, \n",
    "                                         opt_state, \n",
    "                                         loss)\n",
    "    train_loss.append(loss(msg.params, minibatch))\n",
    "    train_acc.append(accuracy(msg.params, minibatch))\n",
    "  # compute and return the change in parameters.\n",
    "  params_update = tree_multimap(lambda x, y: x - y, new_params, msg.params)\n",
    "  \n",
    "  # TODO: replace with an function which constructs message  \n",
    "  msg_to_server = ServerMessage(\n",
    "      aggregator_input=params_update,\n",
    "      stateupdater_input=None\n",
    "  )\n",
    "\n",
    "  diagnostic_msg = DiagnosticsMessage(\n",
    "      train_loss=np.mean(train_loss),\n",
    "      train_acc=np.mean(train_acc),\n",
    "      test_loss=0,\n",
    "      test_acc=1,\n",
    "      weight=len(train_loss)\n",
    "  )\n",
    "  return msg_to_server, diagnostic_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolutely not suitable for jit-compilation.\n",
    "def make_client_data(\n",
    "    ds: tf.data.Dataset,\n",
    "    client_state: ClientState,\n",
    "    hyperparams: ServerHyperParams\n",
    ") -> Tuple[Sequence[Batch], ClientState]:\n",
    "  batches_before, batches_after = [], []\n",
    "  \n",
    "  # Initially skip all the way to client_state.next_idx:\n",
    "  for i, batch in enumerate(ds):\n",
    "    if i < client_state.next_idx:\n",
    "      batches_before.append(\n",
    "        make_jax_batch(batch)\n",
    "      )\n",
    "    # Return once num_batches batches have been selected:\n",
    "    elif len(batches_after) >= hyperparams.max_batches_per_round:\n",
    "      client_state = client_state._replace(next_idx = i)\n",
    "      return batches_after, client_state\n",
    "    # Transform the tf batch to a Batch (Mapping[str, jnp.array])\n",
    "    else:\n",
    "      batches_after.append(\n",
    "        make_jax_batch(batch)\n",
    "      )\n",
    "  \n",
    "  # Increment the client's epoch count once, because we've reached\n",
    "  # the end of the dataset:\n",
    "  client_state = client_state._replace(\n",
    "                            next_idx = 0,\n",
    "                            epoch_count = client_state.epoch_count + 1\n",
    "                            )\n",
    "  \n",
    "  # Traverse the dataset up to max_epochs-1 more times, until num_batches\n",
    "  # batches are in batches_after\n",
    "  for epoch in range(hyperparams.max_epochs_per_round - 1):\n",
    "    \n",
    "    for i, batch in enumerate(ds):\n",
    "      # Return once num_batches batches have been selected:\n",
    "      if len(batches_after) >= hyperparams.max_batches_per_round:\n",
    "        client_state = client_state._replace(next_idx = i)\n",
    "        return batches_after, client_state\n",
    "      # Transform the tf batch to a Batch (Mapping[str, jnp.array])\n",
    "      batches_after.append(\n",
    "        make_jax_batch(batch)\n",
    "      )\n",
    "    \n",
    "    # Increment the client's epoch_count\n",
    "    client_state = client_state._replace(\n",
    "                            next_idx = 0,\n",
    "                            epoch_count = client_state.epoch_count + 1\n",
    "                            )\n",
    "  \n",
    "  # If num_batches has not yet been reached,\n",
    "  # add (some or all of) the batches_before at the end:\n",
    "  num_to_add = hyperparams.max_batches_per_round - len(batches_after)\n",
    "  batches_to_add = batches_before[:num_to_add]\n",
    "  client_state = client_state._replace(next_idx = len(batches_to_add))\n",
    "  batches_after += batches_to_add\n",
    "  return batches_after, client_state\n",
    "\n",
    "def make_all_client_data(\n",
    "    client_data: Sequence[tf.data.Dataset],\n",
    "    client_states: Sequence[ClientState],\n",
    "    hyperparams: ServerHyperParams\n",
    ") -> Tuple[Sequence[Sequence[Batch]], Sequence[ClientState]]:\n",
    "  if not (len(client_states) == len(client_data)):\n",
    "    raise ValueError(\n",
    "        \"Number of datasets ({}) does not fit number of client \"\n",
    "        \"states ({})!\".format(len(client_data), len(client_states))\n",
    "        )\n",
    "  dss_jax, client_states_after = [], []\n",
    "  for ds, client_state_before in zip(client_data, client_states):\n",
    "    batches_jax, client_state_after = make_client_data(ds, client_state_before, hyperparams)\n",
    "    dss_jax.append(batches_jax)\n",
    "    client_states_after.append(client_state_after)\n",
    "  return dss_jax, client_states_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvRbtDM1wS_s"
   },
   "outputs": [],
   "source": [
    "# aggregate client updates.\n",
    "# TODO: make the aggregator stateful.\n",
    "@jax.jit\n",
    "def average_params(params_list: Sequence[hk.Params],\n",
    "                   client_states: Sequence[ClientState],\n",
    "                   hyperparams: AverageAggregatorHyperParams\n",
    "                  ) -> hk.Params: \n",
    "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  num_params = len(params_list)\n",
    "  params_sum = functools.reduce(\n",
    "      lambda t1, t2: tree_multimap(sum, t1, t2), params_list)\n",
    "  params_avg = tree_map(lambda x: x/num_params, params_sum)\n",
    "  return params_avg, client_states\n",
    "\n",
    "@jax.jit\n",
    "def normalize_array_l2(x: jnp.array) -> jnp.array:\n",
    "    print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "    return x / jnp.sqrt(jnp.dot(x, x))\n",
    "\n",
    "@jax.jit\n",
    "def normalize_array_l1(x: jnp.array) -> jnp.array:\n",
    "    print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "    return x / jnp.sum(jnp.abs(x))\n",
    "\n",
    "@jax.jit\n",
    "def tree_norm(tree: hk.Params) -> jnp.array:\n",
    "    print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "    return jnp.sqrt(\n",
    "               jnp.sum(\n",
    "                   tree_leaves(\n",
    "                       tree_map(\n",
    "                           lambda x: jnp.sum(x*x),\n",
    "                           tree\n",
    "                       )\n",
    "                   )\n",
    "               )\n",
    "           )\n",
    "\n",
    "@jax.jit\n",
    "def calc_rel_distances_of_others(reference_update: hk.Params,\n",
    "                                 other_updates: Sequence[hk.Params]\n",
    "                                ) -> Sequence[Any]:\n",
    "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  # Compare the distances to the norm of the reference update.\n",
    "  reference_norm = tree_norm(reference_update)\n",
    "  return [ tree_norm(tree_multimap(lambda x, y: x-y, update, reference_update))\n",
    "           / reference_norm \n",
    "           for update in other_updates ]\n",
    "\n",
    "@jax.partial\n",
    "def sum_args(*args):\n",
    "  print(\"compiling: {} with {} arguments\".format(inspect.currentframe().f_code.co_name, len(args)))\n",
    "  return sum(args)\n",
    "\n",
    "@jax.jit\n",
    "def similarity_aggregator(updates_list: Sequence[hk.Params],\n",
    "                          client_states: Sequence[ClientState],\n",
    "                          hyperparams: SimilarityAggregatorHyperParams\n",
    "                         ) -> Tuple[hk.Params, Sequence[ClientState]]:\n",
    "    print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "    assert len(updates_list) == len(client_states)\n",
    "    reference_update = updates_list[0]\n",
    "    other_updates = updates_list[1:]\n",
    "    rel_distances_of_others = calc_rel_distances_of_others(reference_update,\n",
    "                                                           other_updates)\n",
    "    print(\"rel_distances_of_others:\", rel_distances_of_others)\n",
    "    \n",
    "    # Each dataset starts with a similarity of 1, which can only decrease over time.\n",
    "    # At every round, each dataset's similarity could decrease by something like:\n",
    "    # some_factor * (1+client_state.epoch_count) * rel_distance\n",
    "    for client_id, rel_distance in enumerate(rel_distances_of_others, start=1):\n",
    "        c = client_states[client_id]\n",
    "        print(c.similarity)\n",
    "        decrement = hyperparams.distance_penalty_factor * (1+0.2*c.epoch_count) * rel_distance\n",
    "        similarity = jnp.max([0, c.similarity - decrement]).astype(float)\n",
    "        client_states[client_id] = c._replace(similarity=similarity)\n",
    "    \n",
    "    print([c.similarity for c in client_states])\n",
    "    weights = normalize_array_l1(jnp.array([c.similarity for c in client_states]))\n",
    "    weighted_updates = [tree_map(lambda x: w*x, update) for w, update in zip(weights, updates_list)]\n",
    "    aggregated_update = tree_multimap(sum_args, *weighted_updates)\n",
    "    return aggregated_update, client_states\n",
    "\n",
    "def init_average_aggregator():\n",
    "    return Aggregator(aggregator_function    = average_params,\n",
    "                      aggregator_hyperparams = AverageAggregatorHyperParams()\n",
    "                     )\n",
    "\n",
    "def init_similarity_aggregator(distance_penalty_factor: float = 0.05) -> Aggregator:\n",
    "    similarity_hyperparams = SimilarityAggregatorHyperParams(\n",
    "            distance_penalty_factor=distance_penalty_factor\n",
    "    )\n",
    "    return Aggregator(aggregator_function    = similarity_aggregator,\n",
    "                      aggregator_hyperparams = similarity_hyperparams\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize random generator, params, opt_state.\n",
    "# num_splits = 4\n",
    "# rng = jax.random.PRNGKey(hyperparams.seed)\n",
    "# rngs = jax.random.split(rng, num_splits+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updates_list = [init(rngs[i], dss[0].as_numpy_iterator().next()) for i in range(num_splits+1)]\n",
    "# client_states = [ClientState() for i in range(num_splits+1)]\n",
    "# client_states = similarity_aggregator(updates_list, client_states, SimilarityAggregatorHyperParams(0.05))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     reference_update = init(rngs[-1], dss[0].as_numpy_iterator().next())\n",
    "#     other_updates = [init(rngs[i], dss[0].as_numpy_iterator().next()) for i in range(num_splits)]\n",
    "#     print(calc_rel_distances_of_others(reference_update, other_updates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DeviceArray(1.3672365, dtype=float32), DeviceArray(1.3019154, dtype=float32), DeviceArray(1.5341283, dtype=float32), DeviceArray(1.6079143, dtype=float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     reference_update = init(rngs[0], dss[0].as_numpy_iterator().next())\n",
    "#     other_updates = [init(rngs[i+1], dss[0].as_numpy_iterator().next()) for i in range(num_splits)]\n",
    "#     print(calc_rel_distances_of_others(reference_update, other_updates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running round 0\n",
    "computing updates from active clients.\n",
    "compiling: run_one_step\n",
    "aggregating client updates.\n",
    "compiling: server_updater\n",
    "compiling: extract_from_cout\n",
    "compiling: similarity_aggregator\n",
    "compilinserver_paramsalc_rel_distances_of_others\n",
    "frozendict({\n",
    "  'linear': frozendict({\n",
    "              'b': Traced<ShapedArray(float32[2]):JaxprTrace(level=-1/3)>,\n",
    "              'w': Traced<ShapedArray(float32[9,2]):JaxprTrace(level=-1/3)>,\n",
    "            }),\n",
    "})\n",
    "Traced<ShapedArray(float32[9,2]):JaxprTrace(level=-1/3)>\n",
    "<class 'jax.interpreters.partial_eval.JaxprTracer'> : Traced<ShapedArray(float32[9,2]):JaxprTrace(level=-1/3)>\n",
    "rel_distances_of_others: [Traced<ShapedArray(float32[9,2]):JaxprTrace(level=-1/2)>, Traced<ShapedArray(float32[9,2]):JaxprTrace(level=-1/2)>]\n",
    "Traced<ShapedArray(int32[], weak_type=True):JaxprTrace(level=-1/2)>\n",
    "Traced<ShapedArray(int32[], weak_type=True):JaxprTrace(level=-1/2)>\n",
    "[Traced<ShapedArray(int32[], weak_type=True):JaxprTrace(level=-1/2)>, Traced<ShapedArray(float32[9,2]):JaxprTrace(level=-1/2)>, Traced<ShapedArray(float32[9,2]):JaxprTrace(level=-1/2)>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9V22gJC2DIn"
   },
   "outputs": [],
   "source": [
    "# aggregate diagnositcs.\n",
    "def agg_diagnostics(\n",
    "    client_outputs: Sequence[ClientOutput]) -> DiagnosticsMessage:\n",
    "  d_msgs = extract_from_cout(client_outputs, lambda cout: cout[1])\n",
    "  # TODO: aggregate and report statistics\n",
    "  total_weights = np.sum([msg.weight for msg in d_msgs])\n",
    "\n",
    "  train_loss = np.sum([msg.train_loss for msg in d_msgs]) / total_weights\n",
    "  train_acc =  np.sum([msg.train_acc for msg in d_msgs])  / total_weights\n",
    "  return DiagnosticsMessage(train_loss=train_loss,\n",
    "                            train_acc = train_acc,\n",
    "                            test_loss=0,\n",
    "                            test_acc=1,\n",
    "                            weight=total_weights\n",
    "                           )\n",
    "\n",
    "\n",
    "# update server params.\n",
    "@jax.partial(jax.jit, static_argnums=[3,5])  # fix optimizer and aggregator.\n",
    "def server_updater(\n",
    "    server_params: hk.Params,\n",
    "    client_outputs: Sequence[ClientOutput],\n",
    "    client_states: Sequence[ClientState],\n",
    "    server_opt: optix.InitUpdate,\n",
    "    opt_state: OptState,\n",
    "    aggregator: Aggregator\n",
    ") -> Tuple[hk.Params, Sequence[ClientState], OptState]:\n",
    "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  agg_inputs = extract_from_cout(client_outputs,\n",
    "                                 lambda cout: cout[0].aggregator_input)\n",
    "  agg_update, client_states_out = aggregator.aggregator_function(\n",
    "                                                agg_inputs,\n",
    "                                                client_states,\n",
    "                                                aggregator.aggregator_hyperparams\n",
    "                                                )\n",
    "  eff_grads = tree_map(lambda x: -1.0*x, agg_update)  # effective gradient.\n",
    "  updates, opt_state = server_opt.update(eff_grads, opt_state)\n",
    "  # TODO: allow opt_state to also be explicitly updated by state_updater\n",
    "  server_params = optix.apply_updates(server_params, updates)\n",
    "  return server_params, client_states_out, opt_state\n",
    "\n",
    "# one round of federated learning.\n",
    "def run_one_round(\n",
    "    server_params: hk.Params,\n",
    "    hyperparams: ServerHyperParams,\n",
    "    client_data: Sequence[tf.data.Dataset],\n",
    "    client_states: Sequence[ClientState],\n",
    "    client_opt: optix.InitUpdate,\n",
    "    server_opt: optix.InitUpdate,\n",
    "    opt_state: OptState,\n",
    "    aggregator: Aggregator,\n",
    "    loss: LossFunction,\n",
    "    rng: jax.random.PRNGKey\n",
    ") -> Tuple[hk.Params, Sequence[ClientState], OptState]:\n",
    "  \n",
    "  print(\"computing updates from active clients.\")\n",
    "  # TODO: replace with an function which constructs message\n",
    "  msg_to_clients = ClientMessage(\n",
    "      params=server_params, \n",
    "      opt_init_input=[server_params])\n",
    "  \n",
    "  dss, client_states_upd = make_all_client_data(client_data, client_states, hyperparams)\n",
    "  \n",
    "  client_outputs = list(map(lambda ds: client_updater(\n",
    "                          msg_to_clients,\n",
    "                          ds,\n",
    "                          client_opt,\n",
    "                          loss), dss))\n",
    "  \n",
    "  print(\"aggregating client updates.\")\n",
    "  server_params, client_states_out, opt_state = server_updater(\n",
    "      server_params,\n",
    "      client_outputs,\n",
    "      client_states_upd,\n",
    "      server_opt,      \n",
    "      opt_state,      \n",
    "      aggregator)\n",
    "  \n",
    "  # TODO: aggregate and incporate new diagnostics. needs state!\n",
    "  diagnostics = agg_diagnostics(client_outputs)\n",
    "  \n",
    "  return server_params, client_states_out, opt_state, diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "BuZcD4dEdzF3",
    "outputId": "08edffde-2229-4389-e8b7-bcd7c00320e2"
   },
   "outputs": [],
   "source": [
    "# # Testing one round of federated averaging.\n",
    "# batch_size=10\n",
    "# dss, ds_test = split_by_age(*load_2017annie_predict_EVD(), batch_size)\n",
    "# client_states = init_client_states(dss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "BuZcD4dEdzF3",
    "outputId": "08edffde-2229-4389-e8b7-bcd7c00320e2"
   },
   "outputs": [],
   "source": [
    "# params = init(jax.random.PRNGKey(42), dss[0].as_numpy_iterator().next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "BuZcD4dEdzF3",
    "outputId": "08edffde-2229-4389-e8b7-bcd7c00320e2"
   },
   "outputs": [],
   "source": [
    "# client_opt = optix.sgd(0.1)\n",
    "# server_opt = optix.sgd(1.0)\n",
    "# opt_state = server_opt.init(params)\n",
    "# rng = jax.random.PRNGKey(0)\n",
    "# hyperparams = ServerHyperParams(\n",
    "#     num_rounds = 12,\n",
    "#     max_batches_per_round = 5000,\n",
    "#     max_epochs_per_round = 1,\n",
    "#     batch_size = 10,\n",
    "#     seed = 7\n",
    "# )\n",
    "\n",
    "# run_one_round(\n",
    "#     params,\n",
    "#     hyperparams,\n",
    "#     dss,\n",
    "#     client_states,\n",
    "#     client_opt,\n",
    "#     server_opt,\n",
    "#     opt_state,\n",
    "#     average_params,\n",
    "#     loss,\n",
    "#     rng\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test_accuracy(params: hk.Params, ds: Sequence[Batch]) -> np.float64:\n",
    "    accs = []\n",
    "    for batch in ds:\n",
    "        accs.append(accuracy(params, batch))\n",
    "    return np.mean(accs)\n",
    "\n",
    "def eval_test_loss(params: hk.Params, ds: Sequence[Batch]) -> np.float64:\n",
    "    losses = []\n",
    "    for batch in ds:\n",
    "        losses.append(loss(params, batch))\n",
    "    return np.mean(losses)\n",
    "\n",
    "def make_jax_dataset(ds: tf.data.Dataset) -> Sequence[Batch]:\n",
    "    jax_ds = []\n",
    "    for batch in ds:\n",
    "        jax_ds.append(make_jax_batch(batch))\n",
    "    return jax_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_diagnostics(diag_state: DiagnosticsState,\n",
    "                       diagnostics: DiagnosticsMessage,\n",
    "                       client_states: Sequence[ClientState],\n",
    "                       server_params: hk.Params,\n",
    "                       ds_test: Sequence[Batch]\n",
    "                      ) -> DiagnosticsState:\n",
    "    diag_state_upd = DiagnosticsState(\n",
    "                        train_loss_global     = diag_state.train_loss_global     + [diagnostics.train_loss],\n",
    "                        train_accuracy_global = diag_state.train_accuracy_global + [diagnostics.train_acc],\n",
    "                        test_loss             = diag_state.test_loss     + [eval_test_loss(    server_params, ds_test)],\n",
    "                        test_accuracy         = diag_state.test_accuracy + [eval_test_accuracy(server_params, ds_test)],\n",
    "                        similarities          = diag_state.similarities + [[float(c.similarity) for c in client_states]],\n",
    "                        epoch_counts          = diag_state.epoch_counts + [[int(c.epoch_count) for c in client_states]]\n",
    "                       )\n",
    "    return diag_state_upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsHof54fApTp"
   },
   "outputs": [],
   "source": [
    "def federated_learning(\n",
    "    client_data: Sequence[tf.data.Dataset],\n",
    "     aggregator: Aggregator,\n",
    "        ds_test: Sequence[Batch],\n",
    "    hyperparams: ServerHyperParams,\n",
    "     client_opt: optix.InitUpdate,\n",
    "     server_opt: optix.InitUpdate,\n",
    "           loss: LossFunction,\n",
    "           init\n",
    "    ) -> hk.Params:\n",
    "  # initialize random generator, params, opt_state.\n",
    "  rng = jax.random.PRNGKey(hyperparams.seed)\n",
    "  # TODO: use synthethic data for init\n",
    "  server_params = init(rng, client_data[0].as_numpy_iterator().next())\n",
    "  client_states = init_client_states(client_data)\n",
    "  opt_state = server_opt.init(server_params)\n",
    "  rngs = jax.random.split(rng, hyperparams.num_rounds)\n",
    "  \n",
    "  diag_state = DiagnosticsState()\n",
    "  for round_num, rng in enumerate(rngs):\n",
    "    print(\"\\nrunning round {}\".format(round_num))\n",
    "    server_params, \\\n",
    "    client_states, \\\n",
    "    opt_state,     \\\n",
    "    diagnostics,     = run_one_round(server_params, hyperparams, \n",
    "                                    client_data, client_states, client_opt, \n",
    "                                    server_opt, opt_state, \n",
    "                                    aggregator, loss, rng)\n",
    "    diag_state = update_diagnostics(diag_state, diagnostics, client_states, server_params, ds_test)\n",
    "  \n",
    "  # At each round, the training loss and accuracy are computed based on the\n",
    "  # server_params *before* the round, while the test diagnostics are computed\n",
    "  # from the server_params *after* the round. This is corrected here:\n",
    "  diag_state = diag_state._replace(train_loss_global     = diag_state.train_loss_global[1:],\n",
    "                                   train_accuracy_global = diag_state.train_accuracy_global[1:]\n",
    "                                  )\n",
    "  return server_params, diag_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a federated learning simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "iT-dXeovX2Fd",
    "outputId": "57c040e3-f579-497a-bb96-d30bed2d2004",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/jax/lax/lax.py:4979: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  warnings.warn(msg.format(dtype, fun_name , truncated_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running round 0\n",
      "computing updates from active clients.\n",
      "compiling: run_one_step\n",
      "compiling: loss\n",
      "compiling: loss\n",
      "compiling: accuracy\n",
      "aggregating client updates.\n",
      "compiling: server_updater\n",
      "compiling: extract_from_cout\n",
      "compiling: average_params\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 1\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: server_updater\n",
      "compiling: extract_from_cout\n",
      "compiling: average_params\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 2\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 3\n",
      "computing updates from active clients.\n",
      "compiling: run_one_step\n",
      "compiling: loss\n",
      "compiling: loss\n",
      "compiling: accuracy\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 4\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 5\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 6\n",
      "computing updates from active clients.\n",
      "compiling: run_one_step\n",
      "compiling: loss\n",
      "compiling: loss\n",
      "compiling: accuracy\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 7\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 8\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 9\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 10\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 11\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 12\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 13\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 14\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 15\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 16\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 17\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 18\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 19\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 20\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 21\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 22\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 23\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 24\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 25\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 26\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 27\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 28\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 29\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 0\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: server_updater\n",
      "compiling: extract_from_cout\n",
      "compiling: similarity_aggregator\n",
      "compiling: calc_rel_distances_of_others\n",
      "compiling: tree_norm\n",
      "compiling: tree_norm\n",
      "rel_distances_of_others: [Traced<ShapedArray(float32[]):JaxprTrace(level=-1/2)>, Traced<ShapedArray(float32[]):JaxprTrace(level=-1/2)>]\n",
      "Traced<ShapedArray(float32[], weak_type=True):JaxprTrace(level=-1/2)>\n",
      "Traced<ShapedArray(float32[], weak_type=True):JaxprTrace(level=-1/2)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/jax/lax/lax.py:4979: UserWarning: Explicitly requested dtype <class 'float'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  warnings.warn(msg.format(dtype, fun_name , truncated_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Traced<ShapedArray(float32[], weak_type=True):JaxprTrace(level=-1/2)>, Traced<ShapedArray(float32[]):JaxprTrace(level=-1/2)>, Traced<ShapedArray(float32[]):JaxprTrace(level=-1/2)>]\n",
      "compiling: sum_args with 3 arguments\n",
      "compiling: sum_args with 3 arguments\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 1\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: server_updater\n",
      "compiling: extract_from_cout\n",
      "compiling: similarity_aggregator\n",
      "rel_distances_of_others: [Traced<ShapedArray(float32[]):JaxprTrace(level=-1/2)>, Traced<ShapedArray(float32[]):JaxprTrace(level=-1/2)>]\n",
      "Traced<ShapedArray(float32[]):JaxprTrace(level=-1/2)>\n",
      "Traced<ShapedArray(float32[]):JaxprTrace(level=-1/2)>\n",
      "[Traced<ShapedArray(float32[]):JaxprTrace(level=-1/2)>, Traced<ShapedArray(float32[]):JaxprTrace(level=-1/2)>, Traced<ShapedArray(float32[]):JaxprTrace(level=-1/2)>]\n",
      "compiling: sum_args with 3 arguments\n",
      "compiling: sum_args with 3 arguments\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 2\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 3\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 4\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 5\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 6\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 7\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 8\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 9\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 10\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 11\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 12\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 13\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 14\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 15\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 16\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 17\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 18\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 19\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 20\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 21\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 22\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 23\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 24\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 25\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 26\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 27\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 28\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 29\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 0\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: server_updater\n",
      "compiling: extract_from_cout\n",
      "compiling: average_params\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 1\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: server_updater\n",
      "compiling: extract_from_cout\n",
      "compiling: average_params\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 2\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 3\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 4\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 5\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 6\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 7\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 8\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 9\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 10\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 11\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 12\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 13\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 14\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 15\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 16\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 17\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 18\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 19\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 20\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 21\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 22\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 23\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 24\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 25\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 26\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 27\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 28\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 29\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 0\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 1\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 2\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 3\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 4\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 5\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 6\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 7\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 8\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 9\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 10\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 11\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 12\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 13\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 14\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 15\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 16\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 17\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 18\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 19\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 20\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 21\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 22\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 23\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 24\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 25\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 26\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 27\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 28\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 29\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 0\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 1\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 2\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 3\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 4\n",
      "computing updates from active clients.\n",
      "aggregating client updates.\n",
      "compiling: extract_from_cout\n",
      "\n",
      "running round 5\n",
      "computing updates from active clients.\n"
     ]
    }
   ],
   "source": [
    "# testing federated learning code.\n",
    "\n",
    "hyperparams = ServerHyperParams(\n",
    "    num_rounds = 30,\n",
    "    max_batches_per_round = 3,\n",
    "    max_epochs_per_round = 1,\n",
    "    batch_size = 10,\n",
    "    seed = 420\n",
    ")\n",
    "\n",
    "sim_aggregator = init_similarity_aggregator()\n",
    "avg_aggregator = init_average_aggregator()\n",
    "\n",
    "constant_inputs = (\n",
    "        hyperparams,\n",
    "        optix.sgd(0.1),\n",
    "        optix.sgd(1.0),\n",
    "        loss,\n",
    "        init\n",
    ")\n",
    "\n",
    "client_sets = utils.load(utils.SetLoaders.ANNIE_EVD, utils.Splitters.AGE_SOME, hyperparams.seed)\n",
    "diagnostics = {}\n",
    "for requesting_client in range(len(client_sets)):\n",
    "    dss, ds_test = make_dss(client_sets, hyperparams, requesting_client)\n",
    "    jax_ds_test  = make_jax_dataset(ds_test)\n",
    "    \n",
    "    training_types = {\n",
    "        'global' : (dss,      avg_aggregator),\n",
    "        'similar': (dss,      sim_aggregator),\n",
    "        'local'  : (dss[0:1], avg_aggregator),\n",
    "    }\n",
    "\n",
    "    for key, varied_inputs in training_types.items():\n",
    "        opt_params_global, \\\n",
    "        diag_state          = federated_learning(*varied_inputs,\n",
    "                                                 jax_ds_test,\n",
    "                                                 *constant_inputs\n",
    "                                                );\n",
    "        if not key in diagnostics:\n",
    "            diagnostics[key] = []\n",
    "        diagnostics[key].append( diag_state )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diagnostics['similar'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "markers = {k:v for k,v in zip(diagnostics.keys(), 'ox+svp'*8)}\n",
    "colors = {k:v for k,v in zip(diagnostics.keys(), 'grbkcm'*8)}\n",
    "for key, val in diagnostics.items():\n",
    "    test_acc = [val[i].test_accuracy[-1] for i in range(len(val))]\n",
    "    x = np.arange(len(val))\n",
    "    plt.scatter(x, test_acc, label=key, marker=markers[key], s=60)\n",
    "plt.legend()\n",
    "plt.xlabel('requesting client')\n",
    "plt.ylabel('accuracy on the test set')\n",
    "plt.title(\"Final test accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def average_diag_states(dstates: Sequence[DiagnosticsState]) -> DiagnosticsState:\n",
    "    args = [np.mean([ d[i] for d in dstates], axis=0)\n",
    "            for i in range(len(dstates[0]))]\n",
    "    return DiagnosticsState(*args)\n",
    "    \n",
    "avg_diagnostics = {}\n",
    "for key, dlist in diagnostics.items():\n",
    "    avg_diagnostics[key] = average_diag_states(dlist)\n",
    "avg_diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the evolution of test accuracy and client similarities during training\n",
    "def plot_test_accuracy_and_similarities(diags: Mapping[str, DiagnosticsState], title=''):\n",
    "    fig, ax1 = plt.subplots(figsize=(7,5))\n",
    "    ax1.set_xlabel(\"Communication round\")\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    handles_methods, labels_methods, handles_sim = [], [], []\n",
    "    for key, dstate in diags.items():\n",
    "        m = markers[key]\n",
    "        c = colors[key]\n",
    "        h, = ax1.plot(dstate.test_accuracy, '-'+m+c)\n",
    "        handles_methods.append(h)\n",
    "        labels_methods.append(key)\n",
    "        if key not in ('global', 'local'):\n",
    "            handles_sim = ax1.plot(dstate.similarities, ':')\n",
    "            num_clients = np.array(dstate.similarities).shape[1]\n",
    "            ax2.plot(dstate.epoch_counts, ':')\n",
    "    ax1.set_ylabel(\"Similarity / Test Accuracy\")\n",
    "    ax1.set_ylim((-0.02,1.02))\n",
    "    ax2.set_ylabel(\"Epoch count\")\n",
    "    handles = handles_methods + handles_sim\n",
    "    labels = labels_methods + ['client {}'.format(i) for i in range(num_clients)]\n",
    "    ax1.legend(handles, labels)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaged over the various requesting clients\n",
    "plot_test_accuracy_and_similarities(avg_diagnostics, \"Averaged over the requesting clients (client ordering is lost)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnostics_for_requesting_client(dstates: Mapping[str, Sequence[DiagnosticsState]],\n",
    "                                          requesting_client: int\n",
    "                                         ) -> Mapping[str, DiagnosticsState]:\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        dstates: dict\n",
    "            key: data set selection strategy (e.g., 'global' or 'similar')\n",
    "            value: list of DiagnosticsState. Each DiagnosticsState\n",
    "                   corresponds to one requesting client.\n",
    "        requesting_client: int\n",
    "    \n",
    "    OUTPUTS:\n",
    "        res: dict\n",
    "            key: data set selection strategy (same keys as input `dstates`)\n",
    "            value: DiagnosticsState corresponding to client `requesting_client`.\n",
    "            \n",
    "    The DiagnosticsState.similarities and DiagnosticsState.epoch_counts are reordered,\n",
    "    to maintain the identity of each dataset. For example, the dataset\n",
    "    (, similarity, and epoch_count,) of client 1 are at index 1 irrespectively of\n",
    "    who the requesting client is. This is not the case in the raw training results.\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for key, dlist in diagnostics.items():\n",
    "        dstate = dlist[requesting_client]\n",
    "        similarities = np.array(dstate.similarities)\n",
    "        num_clients = similarities.shape[1]\n",
    "        \n",
    "        indexes_reordered = list(range(1, requesting_client+1)) + [0] + list(range(requesting_client+1, num_clients))\n",
    "        if requesting_client >= num_clients:\n",
    "            indexes_reordered = list(range(num_clients))\n",
    "        \n",
    "        similarities_reordered = np.array(dstate.similarities).T[indexes_reordered].T\n",
    "        epoch_counts_reordered = np.array(dstate.epoch_counts).T[indexes_reordered].T\n",
    "#         print(num_clients, indexes_reordered)\n",
    "#         print(similarities_reordered)\n",
    "        res[key] = dstate._replace(similarities=similarities_reordered,\n",
    "                                   epoch_counts=epoch_counts_reordered\n",
    "                                  )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individually per requesting client\n",
    "for requesting_client in range(len(diagnostics['similar'])):\n",
    "    plot_test_accuracy_and_similarities(\n",
    "        get_diagnostics_for_requesting_client(diagnostics, requesting_client),\n",
    "        \"Requesting client: {}\".format(requesting_client)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EaE23XWAxE2x"
   },
   "source": [
    "# Questions\n",
    "\n",
    "1. Does the net.init also initialize the output layer based on batch size?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Jax federated learning",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
