{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning example with Weight Erosion scheme\n",
    "Based on an earlier version of [Sai Praneeth Karimireddy's Jax-based FL simulation framework](https://colab.research.google.com/drive/1tLFkhmWWbY5veOcqaeXkFbJh9M_4f0hQ) (GitHub: @saipraneet)\n",
    "\n",
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --user git+https://github.com/deepmind/dm-haiku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --user numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --user setGPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages (etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRDenD5M0rDY"
   },
   "outputs": [],
   "source": [
    "from typing import Any, Generator, Tuple, Mapping, Sequence, Optional, Callable, Union, NamedTuple\n",
    "from collections import namedtuple\n",
    "import functools, inspect, time, random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from absl import app\n",
    "import haiku as hk\n",
    "import jax\n",
    "from jax.experimental import optix\n",
    "from jax.tree_util import tree_multimap, tree_map, tree_reduce, tree_leaves\n",
    "import jax.numpy as jnp\n",
    "from jax.lax import fori_loop\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRDenD5M0rDY"
   },
   "outputs": [],
   "source": [
    "from module.custom_types import *\n",
    "import module.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import setGPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc type-related stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-RWB9G48uJA"
   },
   "outputs": [],
   "source": [
    "# extracts messages from a list of client outputs.\n",
    "# @jax.partial(jax.jit, static_argnums=[1])  # fix extractor.\n",
    "def extract_from_cout(\n",
    "    couts: Sequence[ClientOutput],\n",
    "    extractor: Callable[[ClientOutput], Any]\n",
    "    ) -> Sequence[Any]:\n",
    "#   print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  # TODO: use pytrees.transpose?\n",
    "  # msgs = fori_loop(0, len(couts),\n",
    "  #                    lambda i, msgs: msgs.append(extractor(couts[i])), [])\n",
    "  msgs = [extractor(cout) for cout in couts]\n",
    "  return msgs\n",
    "\n",
    "def init_client_states(client_data: Sequence[tf.data.Dataset]) -> Sequence[ClientState]:\n",
    "  return [ClientState() for i in range(len(client_data))]\n",
    "\n",
    "def make_jax_batch(batch: Mapping[str, tf.Tensor]) -> Batch:\n",
    "    \"\"\"Transform a Mapping[str, tf.Tensor] (tensorflow batch)\n",
    "    into a Mapping[str, jnp.array] (jax-compatible batch).\"\"\"\n",
    "    jax_batch = {}\n",
    "    for key in batch:\n",
    "        jax_batch[key] = jnp.array(batch[key].numpy(), dtype=np.float32)\n",
    "    return jax_batch\n",
    "\n",
    "def make_jax_dataset(ds: tf.data.Dataset) -> Sequence[Batch]:\n",
    "    jax_ds = []\n",
    "    for batch in ds:\n",
    "        jax_ds.append(make_jax_batch(batch))\n",
    "    return jax_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch the data sets and create the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dss(clients: Sequence[Tuple[np.ndarray, np.ndarray]],\n",
    "             hyperparams: ServerHyperParams,\n",
    "             requesting_client: int = 0,\n",
    "             test_ratio: float = 0.5\n",
    ") -> Tuple[DatasetSequence, tf.data.Dataset]:\n",
    "    \"\"\"Make batched `tf.data.Dataset`s based on the (X,y) tuples representing\n",
    "    each client's data. \n",
    "    \n",
    "    requesting_client: Index of the age group for which a test set is created.\n",
    "    The training set for the requesting client is placed at index 0 in the returned\n",
    "    DatasetSequence.\"\"\"\n",
    "    if requesting_client < 0 or requesting_client >= len(clients):\n",
    "        raise ValueError(\"Unexpected 'requesting_client' argument: \"\n",
    "                         \"Expecting a non-negative int lower than \"\n",
    "                         \"{}.\".format(len(clients)))\n",
    "    \n",
    "    dss, ds_test = [None], None\n",
    "    for i, (X,y) in enumerate(clients):\n",
    "        if i == requesting_client:\n",
    "            test_size = 1 + int(y.shape[0] * test_ratio)\n",
    "            ds_test = utils.make_ds(X[:test_size], y[:test_size], hyperparams.batch_size)\n",
    "            dss[0] = utils.make_ds(X[test_size:], y[test_size:], hyperparams.batch_size)\n",
    "        else:\n",
    "            dss.append( utils.make_ds(X, y, hyperparams.batch_size) )\n",
    "    \n",
    "    assert (ds_test is not None)\n",
    "    \n",
    "    return dss, ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams = ServerHyperParams(\n",
    "#     num_rounds = 30,\n",
    "#     max_batches_per_round = 3,\n",
    "#     max_epochs_per_round = 1,\n",
    "#     batch_size = 10,\n",
    "#     seed = 420\n",
    "# )\n",
    "# dss, ds_test = make_dss(split_by_age(*load_2017annie_predict_EVD()), hyperparams)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in ds_test:\n",
    "#     print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model, loss function, training, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbTmc5DwjoON"
   },
   "outputs": [],
   "source": [
    "# Neural network model.\n",
    "def net_fn(batch: Batch) -> jnp.ndarray:\n",
    "  \"\"\"Logistic regression for 2-class classification.\"\"\"\n",
    "  x = batch[\"features\"]\n",
    "  logistic_reg = hk.Sequential([\n",
    "      hk.Flatten(),\n",
    "      hk.Linear(2, with_bias=True), jax.nn.log_softmax\n",
    "  ])\n",
    "  return logistic_reg(x)\n",
    "net: hk.Transformed = hk.transform(net_fn)\n",
    "\n",
    "# Initialize neural network parameters \n",
    "def init(rng: jax.random.PRNGKey, batch: Batch) -> hk.Params:\n",
    "  return net.init(rng, batch)\n",
    "\n",
    "# get predictions from model.\n",
    "def forward(params: hk.Params, batch: Batch):\n",
    "  return jax.jit(net.apply)(params, batch)\n",
    "\n",
    "\n",
    "# Training loss (cross-entropy).\n",
    "@jax.jit\n",
    "def loss(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
    "  \"\"\"Compute the loss of the network, including L2.\"\"\"\n",
    "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  preds = forward(params, batch)\n",
    "  labels = hk.one_hot(batch[\"label\"], 2)\n",
    "  # TODO: Put weight decay into optimizer\n",
    "  l2_loss = 0.5 * sum(jnp.sum(jnp.square(p)) for p in jax.tree_leaves(params))\n",
    "  softmax_xent = -jnp.mean(labels * preds, dtype=np.float32)\n",
    "  return softmax_xent+ 1e-3 * l2_loss\n",
    "\n",
    "# Evaluation metric (classification accuracy).\n",
    "@jax.jit\n",
    "def accuracy(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
    "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  preds = forward(params, batch)\n",
    "  pred_class = jnp.argmax(preds, axis=-1)\n",
    "  print(pred_class)\n",
    "  return jnp.mean(pred_class == batch[\"label\"], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elJQ6h8MVeH6"
   },
   "outputs": [],
   "source": [
    "# one local update step.\n",
    "@jax.partial(jax.jit, static_argnums=[2,4])  # fix loss function and optimizer.\n",
    "def run_one_step(\n",
    "    params: hk.Params,\n",
    "    batch: Batch,\n",
    "    client_opt: optix.InitUpdate,\n",
    "    opt_state: OptState,\n",
    "    loss: LossFunction\n",
    "    ) -> Tuple[hk.Params, OptState]:\n",
    "  \"\"\"Learning rule (stochastic gradient descent).\"\"\"\n",
    "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  grads = jax.grad(loss)(params, batch)\n",
    "  updates, opt_state = client_opt.update(grads, opt_state)\n",
    "  new_params = optix.apply_updates(params, updates)\n",
    "  return new_params, opt_state\n",
    "\n",
    "# perform client updates.\n",
    "def client_updater(\n",
    "    msg: ClientMessage,\n",
    "    ds: Sequence[Batch],\n",
    "    client_opt: optix.InitUpdate,\n",
    "    loss: LossFunction\n",
    "    ) -> ClientOutput:\n",
    "  opt_state = client_opt.init(*msg.opt_init_input)\n",
    "  # iterate through data making updates.\n",
    "  new_params = msg.params\n",
    "  train_loss, train_acc = [], []\n",
    "  for minibatch in ds:\n",
    "    new_params, opt_state = run_one_step(new_params,\n",
    "                                         minibatch,\n",
    "                                         client_opt, \n",
    "                                         opt_state, \n",
    "                                         loss)\n",
    "    train_loss.append(loss(msg.params, minibatch))\n",
    "    train_acc.append(accuracy(msg.params, minibatch))\n",
    "  # compute and return the change in parameters.\n",
    "  params_update = tree_multimap(lambda x, y: x - y, new_params, msg.params)\n",
    "  \n",
    "  # TODO: replace with an function which constructs message  \n",
    "  msg_to_server = ServerMessage(\n",
    "      aggregator_input=params_update,\n",
    "      stateupdater_input=None\n",
    "  )\n",
    "\n",
    "  diagnostic_msg = DiagnosticsMessage(\n",
    "      train_loss=np.mean(train_loss),\n",
    "      train_acc=np.mean(train_acc),\n",
    "      test_loss=0,\n",
    "      test_acc=1,\n",
    "      weight=len(train_loss)\n",
    "  )\n",
    "  return msg_to_server, diagnostic_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make clients stateful (remember which batch is up next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolutely not suitable for jit-compilation.\n",
    "def make_client_data(\n",
    "    ds: tf.data.Dataset,\n",
    "    client_state: ClientState,\n",
    "    hyperparams: ServerHyperParams\n",
    ") -> Tuple[Sequence[Batch], ClientState]:\n",
    "  \"\"\"Picks out and assembles the batches used in the next round\n",
    "  for one client, updating the client state along the way.\n",
    "  \"\"\"\n",
    "  batches_before, batches_after = [], []\n",
    "  \n",
    "  # Initially skip all the way to client_state.next_idx:\n",
    "  for i, batch in enumerate(ds):\n",
    "    if i < client_state.next_idx:\n",
    "      batches_before.append(\n",
    "        make_jax_batch(batch)\n",
    "      )\n",
    "    # Return once num_batches batches have been selected:\n",
    "    elif len(batches_after) >= hyperparams.max_batches_per_round:\n",
    "      client_state = client_state._replace(next_idx = i)\n",
    "      return batches_after, client_state\n",
    "    # Transform the tf batch to a Batch (Mapping[str, jnp.array])\n",
    "    else:\n",
    "      batches_after.append(\n",
    "        make_jax_batch(batch)\n",
    "      )\n",
    "  \n",
    "  # Increment the client's epoch count once, because we've reached\n",
    "  # the end of the dataset:\n",
    "  client_state = client_state._replace(\n",
    "                            next_idx = 0,\n",
    "                            epoch_count = client_state.epoch_count + 1\n",
    "                            )\n",
    "  \n",
    "  # Traverse the dataset up to max_epochs-1 more times, until num_batches\n",
    "  # batches are in batches_after\n",
    "  for epoch in range(hyperparams.max_epochs_per_round - 1):\n",
    "    \n",
    "    for i, batch in enumerate(ds):\n",
    "      # Return once num_batches batches have been selected:\n",
    "      if len(batches_after) >= hyperparams.max_batches_per_round:\n",
    "        client_state = client_state._replace(next_idx = i)\n",
    "        return batches_after, client_state\n",
    "      # Transform the tf batch to a Batch (Mapping[str, jnp.array])\n",
    "      batches_after.append(\n",
    "        make_jax_batch(batch)\n",
    "      )\n",
    "    \n",
    "    # Increment the client's epoch_count\n",
    "    client_state = client_state._replace(\n",
    "                            next_idx = 0,\n",
    "                            epoch_count = client_state.epoch_count + 1\n",
    "                            )\n",
    "  \n",
    "  # If num_batches has not yet been reached,\n",
    "  # add (some or all of) the batches_before at the end:\n",
    "  num_to_add = hyperparams.max_batches_per_round - len(batches_after)\n",
    "  batches_to_add = batches_before[:num_to_add]\n",
    "  client_state = client_state._replace(next_idx = len(batches_to_add))\n",
    "  batches_after += batches_to_add\n",
    "  return batches_after, client_state\n",
    "\n",
    "def make_all_client_data(\n",
    "    client_data: Sequence[tf.data.Dataset],\n",
    "    client_states: Sequence[ClientState],\n",
    "    hyperparams: ServerHyperParams\n",
    ") -> Tuple[Sequence[Sequence[Batch]], Sequence[ClientState]]:\n",
    "  \"\"\"Picks out and assembles the batches used in the next round\n",
    "  for all clients, updating their states along the way.\n",
    "  \"\"\"\n",
    "  if not (len(client_states) == len(client_data)):\n",
    "    raise ValueError(\n",
    "        \"Number of datasets ({}) does not fit number of client \"\n",
    "        \"states ({})!\".format(len(client_data), len(client_states))\n",
    "        )\n",
    "  dss_jax, client_states_after = [], []\n",
    "  for ds, client_state_before in zip(client_data, client_states):\n",
    "    batches_jax, client_state_after = make_client_data(ds, client_state_before, hyperparams)\n",
    "    dss_jax.append(batches_jax)\n",
    "    client_states_after.append(client_state_after)\n",
    "  return dss_jax, client_states_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvRbtDM1wS_s"
   },
   "outputs": [],
   "source": [
    "# aggregate client updates.\n",
    "# TODO: make the aggregator stateful.\n",
    "@jax.jit\n",
    "def average_params(params_list: Sequence[hk.Params],\n",
    "                   client_states: Sequence[ClientState],\n",
    "                   hyperparams: AverageAggregatorHyperParams\n",
    "                  ) -> hk.Params: \n",
    "  print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  num_params = len(params_list)\n",
    "  params_sum = functools.reduce(\n",
    "      lambda t1, t2: tree_multimap(sum, t1, t2), params_list)\n",
    "  params_avg = tree_map(lambda x: x/num_params, params_sum)\n",
    "  return params_avg, client_states\n",
    "\n",
    "@jax.jit\n",
    "def normalize_array_l2(x: jnp.array) -> jnp.array:\n",
    "    print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "    return x / jnp.sqrt(jnp.dot(x, x))\n",
    "\n",
    "@jax.jit\n",
    "def normalize_array_l1(x: jnp.array) -> jnp.array:\n",
    "    print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "    return x / jnp.sum(jnp.abs(x))\n",
    "\n",
    "@jax.jit\n",
    "def tree_norm(tree: hk.Params) -> jnp.array:\n",
    "    print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "    return jnp.sqrt(\n",
    "               jnp.sum(\n",
    "                   tree_leaves(\n",
    "                       tree_map(\n",
    "                           lambda x: jnp.sum(x*x),\n",
    "                           tree\n",
    "                       )\n",
    "                   )\n",
    "               )\n",
    "           )\n",
    "\n",
    "# @jax.jit\n",
    "def calc_rel_distances_of_others(reference_update: hk.Params,\n",
    "                                 other_updates: Sequence[hk.Params]\n",
    "                                ) -> Sequence[Any]:\n",
    "#   print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  # Compare the distances to the norm of the reference update.\n",
    "  reference_norm = tree_norm(reference_update)\n",
    "  return [ tree_norm(tree_multimap(lambda x, y: x-y, update, reference_update))\n",
    "           / reference_norm \n",
    "           for update in other_updates ]\n",
    "\n",
    "# @jax.partial\n",
    "def sum_args(*args):\n",
    "#   print(\"compiling: {} with {} arguments\".format(inspect.currentframe().f_code.co_name, len(args)))\n",
    "  return sum(args)\n",
    "\n",
    "# @jax.jit\n",
    "def similarity_aggregator(updates_list: Sequence[hk.Params],\n",
    "                          client_states: Sequence[ClientState],\n",
    "                          hyperparams: SimilarityAggregatorHyperParams\n",
    "                         ) -> Tuple[hk.Params, Sequence[ClientState]]:\n",
    "#     print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "    assert len(updates_list) == len(client_states)\n",
    "    reference_update = updates_list[0]\n",
    "    other_updates = updates_list[1:]\n",
    "    rel_distances_of_others = calc_rel_distances_of_others(reference_update,\n",
    "                                                           other_updates)\n",
    "    print(\"rel_distances_of_others:\", rel_distances_of_others)\n",
    "    \n",
    "    # Each dataset starts with a similarity of 1, which can only decrease over time.\n",
    "    # At every round, each dataset's similarity could decrease by something like:\n",
    "    # some_factor * (1+client_state.epoch_count) * rel_distance\n",
    "    for client_id, rel_distance in enumerate(rel_distances_of_others, start=1):\n",
    "        c = client_states[client_id]\n",
    "        print(c.similarity)\n",
    "        decrement = hyperparams.distance_penalty_factor * (1+0.2*c.epoch_count) * rel_distance\n",
    "        similarity = jnp.max([0, c.similarity - decrement], dtype=np.float32).astype(np.float32)\n",
    "        client_states[client_id] = c._replace(similarity=similarity)\n",
    "    \n",
    "    print([c.similarity for c in client_states])\n",
    "    weights = normalize_array_l1(jnp.array([c.similarity for c in client_states], dtype=np.float32))\n",
    "    weighted_updates = [tree_map(lambda x: w*x, update) for w, update in zip(weights, updates_list)]\n",
    "    aggregated_update = tree_multimap(sum_args, *weighted_updates)\n",
    "    return aggregated_update, client_states\n",
    "\n",
    "def init_average_aggregator():\n",
    "    return Aggregator(aggregator_function    = average_params,\n",
    "                      aggregator_hyperparams = AverageAggregatorHyperParams()\n",
    "                     )\n",
    "\n",
    "def init_similarity_aggregator(distance_penalty_factor: float = 0.05) -> Aggregator:\n",
    "    similarity_hyperparams = SimilarityAggregatorHyperParams(\n",
    "            distance_penalty_factor=distance_penalty_factor\n",
    "    )\n",
    "    return Aggregator(aggregator_function    = similarity_aggregator,\n",
    "                      aggregator_hyperparams = similarity_hyperparams\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize random generator, params, opt_state.\n",
    "# num_splits = 4\n",
    "# rng = jax.random.PRNGKey(hyperparams.seed)\n",
    "# rngs = jax.random.split(rng, num_splits+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updates_list = [init(rngs[i], dss[0].as_numpy_iterator().next()) for i in range(num_splits+1)]\n",
    "# client_states = [ClientState() for i in range(num_splits+1)]\n",
    "# client_states = similarity_aggregator(updates_list, client_states, SimilarityAggregatorHyperParams(0.05))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     reference_update = init(rngs[-1], dss[0].as_numpy_iterator().next())\n",
    "#     other_updates = [init(rngs[i], dss[0].as_numpy_iterator().next()) for i in range(num_splits)]\n",
    "#     print(calc_rel_distances_of_others(reference_update, other_updates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DeviceArray(1.3672365, dtype=float32), DeviceArray(1.3019154, dtype=float32), DeviceArray(1.5341283, dtype=float32), DeviceArray(1.6079143, dtype=float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     reference_update = init(rngs[0], dss[0].as_numpy_iterator().next())\n",
    "#     other_updates = [init(rngs[i+1], dss[0].as_numpy_iterator().next()) for i in range(num_splits)]\n",
    "#     print(calc_rel_distances_of_others(reference_update, other_updates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One round of training & communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9V22gJC2DIn"
   },
   "outputs": [],
   "source": [
    "# aggregate diagnositcs.\n",
    "def agg_diagnostics(\n",
    "    client_outputs: Sequence[ClientOutput]) -> DiagnosticsMessage:\n",
    "  d_msgs = extract_from_cout(client_outputs, lambda cout: cout[1])\n",
    "  # TODO: aggregate and report statistics\n",
    "  total_weights = np.sum([msg.weight for msg in d_msgs])\n",
    "\n",
    "  train_loss = np.sum([msg.train_loss for msg in d_msgs]) / total_weights\n",
    "  train_acc =  np.sum([msg.train_acc for msg in d_msgs])  / total_weights\n",
    "  return DiagnosticsMessage(train_loss=train_loss,\n",
    "                            train_acc = train_acc,\n",
    "                            test_loss=0,\n",
    "                            test_acc=1,\n",
    "                            weight=total_weights\n",
    "                           )\n",
    "\n",
    "\n",
    "# update server params.\n",
    "# @jax.partial(jax.jit, static_argnums=[3,5])  # fix optimizer and aggregator.\n",
    "def server_updater(\n",
    "    server_params: hk.Params,\n",
    "    client_outputs: Sequence[ClientOutput],\n",
    "    client_states: Sequence[ClientState],\n",
    "    server_opt: optix.InitUpdate,\n",
    "    opt_state: OptState,\n",
    "    aggregator: Aggregator\n",
    ") -> Tuple[hk.Params, Sequence[ClientState], OptState]:\n",
    "#   print(\"compiling: {}\".format(inspect.currentframe().f_code.co_name))\n",
    "  agg_inputs = extract_from_cout(client_outputs,\n",
    "                                 lambda cout: cout[0].aggregator_input)\n",
    "  agg_update, client_states_out = aggregator.aggregator_function(\n",
    "                                                agg_inputs,\n",
    "                                                client_states,\n",
    "                                                aggregator.aggregator_hyperparams\n",
    "                                                )\n",
    "  eff_grads = tree_map(lambda x: -1.0*x, agg_update)  # effective gradient.\n",
    "  updates, opt_state = server_opt.update(eff_grads, opt_state)\n",
    "  # TODO: allow opt_state to also be explicitly updated by state_updater\n",
    "  server_params = optix.apply_updates(server_params, updates)\n",
    "  return server_params, client_states_out, opt_state\n",
    "\n",
    "# one round of federated learning.\n",
    "def run_one_round(\n",
    "    server_params: hk.Params,\n",
    "    hyperparams: ServerHyperParams,\n",
    "    client_data: Sequence[tf.data.Dataset],\n",
    "    client_states: Sequence[ClientState],\n",
    "    client_opt: optix.InitUpdate,\n",
    "    server_opt: optix.InitUpdate,\n",
    "    opt_state: OptState,\n",
    "    aggregator: Aggregator,\n",
    "    loss: LossFunction,\n",
    "    rng: jax.random.PRNGKey\n",
    ") -> Tuple[hk.Params, Sequence[ClientState], OptState]:\n",
    "  \n",
    "  print(\"computing updates from active clients.\")\n",
    "  # TODO: replace with an function which constructs message\n",
    "  msg_to_clients = ClientMessage(\n",
    "      params=server_params, \n",
    "      opt_init_input=[server_params])\n",
    "  \n",
    "  dss, client_states_upd = make_all_client_data(client_data, client_states, hyperparams)\n",
    "  \n",
    "  client_outputs = list(map(lambda ds: client_updater(\n",
    "                          msg_to_clients,\n",
    "                          ds,\n",
    "                          client_opt,\n",
    "                          loss), dss))\n",
    "  \n",
    "  print(\"aggregating client updates.\")\n",
    "  server_params, client_states_out, opt_state = server_updater(\n",
    "      server_params,\n",
    "      client_outputs,\n",
    "      client_states_upd,\n",
    "      server_opt,      \n",
    "      opt_state,      \n",
    "      aggregator)\n",
    "  \n",
    "  # TODO: aggregate and incporate new diagnostics. needs state!\n",
    "  diagnostics = agg_diagnostics(client_outputs)\n",
    "  \n",
    "  return server_params, client_states_out, opt_state, diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "BuZcD4dEdzF3",
    "outputId": "08edffde-2229-4389-e8b7-bcd7c00320e2"
   },
   "outputs": [],
   "source": [
    "# # Testing one round of federated averaging.\n",
    "# batch_size=10\n",
    "# dss, ds_test = split_by_age(*load_2017annie_predict_EVD(), batch_size)\n",
    "# client_states = init_client_states(dss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "BuZcD4dEdzF3",
    "outputId": "08edffde-2229-4389-e8b7-bcd7c00320e2"
   },
   "outputs": [],
   "source": [
    "# params = init(jax.random.PRNGKey(42), dss[0].as_numpy_iterator().next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "BuZcD4dEdzF3",
    "outputId": "08edffde-2229-4389-e8b7-bcd7c00320e2"
   },
   "outputs": [],
   "source": [
    "# client_opt = optix.sgd(0.1)\n",
    "# server_opt = optix.sgd(1.0)\n",
    "# opt_state = server_opt.init(params)\n",
    "# rng = jax.random.PRNGKey(0)\n",
    "# hyperparams = ServerHyperParams(\n",
    "#     num_rounds = 12,\n",
    "#     max_batches_per_round = 5000,\n",
    "#     max_epochs_per_round = 1,\n",
    "#     batch_size = 10,\n",
    "#     seed = 7\n",
    "# )\n",
    "\n",
    "# run_one_round(\n",
    "#     params,\n",
    "#     hyperparams,\n",
    "#     dss,\n",
    "#     client_states,\n",
    "#     client_opt,\n",
    "#     server_opt,\n",
    "#     opt_state,\n",
    "#     average_params,\n",
    "#     loss,\n",
    "#     rng\n",
    "# );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test_accuracy(params: hk.Params, ds: Sequence[Batch]) -> np.float64:\n",
    "    accs = []\n",
    "    for batch in ds:\n",
    "        accs.append(accuracy(params, batch))\n",
    "    return np.mean(accs)\n",
    "\n",
    "def one_hot_encode(labels, n_classes):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : labels: List of sample labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "     \"\"\"\n",
    "    targets = np.array(labels, dtype=np.int8).reshape(-1)\n",
    "    return np.eye(n_classes)[targets]\n",
    "\n",
    "# Baseline classification accuracy (prevalence of most prevalent label)\n",
    "def eval_baseline_test_accuracy(ds: tf.data.Dataset) -> np.float64:\n",
    "    labels = one_hot_encode(np.concatenate([batch[\"label\"] for batch in ds], axis=0), 2)\n",
    "    return np.max(labels.mean(axis=0))\n",
    "\n",
    "def eval_test_loss(params: hk.Params, ds: Sequence[Batch]) -> np.float64:\n",
    "    losses = []\n",
    "    for batch in ds:\n",
    "        losses.append(loss(params, batch))\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_diagnostics(diag_state: DiagnosticsState,\n",
    "                       diagnostics: DiagnosticsMessage,\n",
    "                       client_states: Sequence[ClientState],\n",
    "                       server_params: hk.Params,\n",
    "                       ds_test: Sequence[Batch]\n",
    "                      ) -> DiagnosticsState:\n",
    "    diag_state_upd = DiagnosticsState(\n",
    "                        train_loss_global     = diag_state.train_loss_global     + [diagnostics.train_loss],\n",
    "                        train_accuracy_global = diag_state.train_accuracy_global + [diagnostics.train_acc],\n",
    "                        test_loss             = diag_state.test_loss     + [eval_test_loss(    server_params, ds_test)],\n",
    "                        test_accuracy         = diag_state.test_accuracy + [eval_test_accuracy(server_params, ds_test)],\n",
    "                        similarities          = diag_state.similarities + [[float(c.similarity) for c in client_states]],\n",
    "                        epoch_counts          = diag_state.epoch_counts + [[int(c.epoch_count) for c in client_states]]\n",
    "                       )\n",
    "    return diag_state_upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsHof54fApTp"
   },
   "outputs": [],
   "source": [
    "def federated_learning(\n",
    "    client_data: Sequence[tf.data.Dataset],\n",
    "     aggregator: Aggregator,\n",
    "        ds_test: Sequence[Batch],\n",
    "    hyperparams: ServerHyperParams,\n",
    "     client_opt: optix.InitUpdate,\n",
    "     server_opt: optix.InitUpdate,\n",
    "           loss: LossFunction,\n",
    "           init\n",
    "    ) -> hk.Params:\n",
    "  # initialize random generator, params, opt_state.\n",
    "  rng = jax.random.PRNGKey(hyperparams.seed)\n",
    "  # TODO: use synthethic data for init\n",
    "  server_params = init(rng, client_data[0].as_numpy_iterator().next())\n",
    "  client_states = init_client_states(client_data)\n",
    "  opt_state = server_opt.init(server_params)\n",
    "  rngs = jax.random.split(rng, hyperparams.num_rounds)\n",
    "  \n",
    "  diag_state = DiagnosticsState()\n",
    "  for round_num, rng in enumerate(rngs):\n",
    "    print(\"\\nrunning round {}\".format(round_num))\n",
    "    server_params, \\\n",
    "    client_states, \\\n",
    "    opt_state,     \\\n",
    "    diagnostics,     = run_one_round(server_params, hyperparams, \n",
    "                                    client_data, client_states, client_opt, \n",
    "                                    server_opt, opt_state, \n",
    "                                    aggregator, loss, rng)\n",
    "    diag_state = update_diagnostics(diag_state, diagnostics, client_states, server_params, ds_test)\n",
    "  \n",
    "  # At each round, the training loss and accuracy are computed based on the\n",
    "  # server_params *before* the round, while the test diagnostics are computed\n",
    "  # from the server_params *after* the round. This is corrected here:\n",
    "  diag_state = diag_state._replace(train_loss_global     = diag_state.train_loss_global[1:],\n",
    "                                   train_accuracy_global = diag_state.train_accuracy_global[1:]\n",
    "                                  )\n",
    "  return server_params, diag_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a federated learning simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "iT-dXeovX2Fd",
    "outputId": "57c040e3-f579-497a-bb96-d30bed2d2004",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing federated learning code.\n",
    "\n",
    "hyperparams = ServerHyperParams(\n",
    "    num_rounds = 30,\n",
    "    max_batches_per_round = 1,\n",
    "    max_epochs_per_round = 1,\n",
    "    batch_size = 125,\n",
    "    seed = 278\n",
    ")\n",
    "\n",
    "sim_aggregator = init_similarity_aggregator(0.01)\n",
    "avg_aggregator = init_average_aggregator()\n",
    "\n",
    "constant_inputs = {\n",
    "        'hyperparams': hyperparams,\n",
    "        'server_opt': optix.sgd(1.0),\n",
    "        'loss': loss,\n",
    "        'init': init\n",
    "}\n",
    "\n",
    "random.seed(hyperparams.seed)\n",
    "client_sets = utils.load(utils.SetLoaders.ANNIE_EVD, utils.Splitters.AGE_SOME, hyperparams.seed)\n",
    "diagnostics = {}\n",
    "baseline_test_accuracies = []\n",
    "for requesting_client in range(len(client_sets)):\n",
    "    dss, ds_test = make_dss(client_sets, hyperparams, requesting_client)\n",
    "    jax_ds_test  = make_jax_dataset(ds_test)\n",
    "    \n",
    "    training_types = {\n",
    "        'global': {'client_data': dss,\n",
    "                   'aggregator' : avg_aggregator,\n",
    "                   'client_opt' : optix.sgd(0.1)\n",
    "                  },\n",
    "        'similar': {'client_data': dss,\n",
    "                    'aggregator' : sim_aggregator,\n",
    "                    'client_opt' : optix.sgd(3.0)\n",
    "                   },\n",
    "        'local'  : {'client_data': dss[0:1],\n",
    "                    'aggregator' : avg_aggregator,\n",
    "                    'client_opt' : optix.sgd(3.0)\n",
    "                   },\n",
    "    }\n",
    "    \n",
    "    baseline_test_accuracies.append(eval_baseline_test_accuracy(ds_test))\n",
    "    print(\"CLIENT {} baseline test accuracy: {:.3f}\".format(requesting_client, baseline_test_accuracies[-1]))\n",
    "\n",
    "    for key, varied_inputs in training_types.items():\n",
    "        print('\\n'*2, '-'*15, 'TRAINING WITH {} AGGREGATOR FOR REQUESTING CLIENT = {}'.format(key, requesting_client), '-'*15)\n",
    "        opt_params_global, \\\n",
    "        diag_state          = federated_learning(ds_test = jax_ds_test,\n",
    "                                                 **varied_inputs,\n",
    "                                                 **constant_inputs\n",
    "                                                );\n",
    "        if not key in diagnostics:\n",
    "            diagnostics[key] = []\n",
    "        diagnostics[key].append( diag_state )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diagnostics['similar'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "markers = {k:v for k,v in zip(diagnostics.keys(), 'ox+svp'*8)}\n",
    "colors = {k:v for k,v in zip(diagnostics.keys(), 'gbkcm'*8)}\n",
    "\n",
    "def final_scatter(accuracies, **kwargs):\n",
    "    plt.scatter(np.arange(len(accuracies)), accuracies, s=60, **kwargs)\n",
    "\n",
    "final_scatter(baseline_test_accuracies, label='baseline test accuracy', marker='_', c='r')\n",
    "\n",
    "for key, val in diagnostics.items():\n",
    "    test_acc = [val[i].test_accuracy[-1] for i in range(len(val))]\n",
    "    x = np.arange(len(val))\n",
    "    final_scatter(test_acc, label=key, marker=markers[key], c=colors[key])\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('requesting client')\n",
    "plt.ylabel('accuracy on the test set')\n",
    "plt.title(\"Final test accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def average_diag_states(dstates: Sequence[DiagnosticsState]) -> DiagnosticsState:\n",
    "    args = [np.mean([ d[i] for d in dstates], axis=0)\n",
    "            for i in range(len(dstates[0]))]\n",
    "    return DiagnosticsState(*args)\n",
    "    \n",
    "avg_diagnostics = {}\n",
    "for key, dlist in diagnostics.items():\n",
    "    avg_diagnostics[key] = average_diag_states(dlist)\n",
    "avg_diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the evolution of test accuracy and client similarities during training\n",
    "def plot_test_accuracy_and_similarities(diags: Mapping[str, DiagnosticsState], baseline, title=''):\n",
    "    fig, ax1 = plt.subplots(figsize=(9,7))\n",
    "    ax1.set_xlabel(\"Communication round\")\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    h = ax1.axhline(baseline, color='r', linestyle='dashed')\n",
    "    ax1.axhline(1-baseline, color='r', linestyle='dashed')\n",
    "    \n",
    "    handles_methods, labels_methods, handles_sim, labels_sim = [h], ['baseline accuracy'], [], []\n",
    "    for key, dstate in diags.items():\n",
    "        m = markers[key]\n",
    "        c = colors[key]\n",
    "        h, = ax1.plot(dstate.test_accuracy, '-'+m+c)\n",
    "        handles_methods.append(h)\n",
    "        labels_methods.append(key)\n",
    "        if key not in ('global', 'local'):\n",
    "            handles_sim = ax1.plot(dstate.similarities, ':')\n",
    "            num_clients = np.array(dstate.similarities).shape[1]\n",
    "            ax2.plot(dstate.epoch_counts, ':')\n",
    "    ax1.set_ylabel(\"Similarity / Test Accuracy\")\n",
    "    ax1.set_ylim((-0.02,1.02))\n",
    "    ax2.set_ylabel(\"Epoch count\")\n",
    "    handles = handles_methods + handles_sim\n",
    "    if handles_sim:\n",
    "        labels_sim = ['client {}'.format(i) for i in range(num_clients)]\n",
    "    labels = labels_methods + labels_sim\n",
    "    ax1.legend(handles, labels)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaged over the various requesting clients\n",
    "plot_test_accuracy_and_similarities(avg_diagnostics, np.mean(baseline_test_accuracies), \"Averaged over the requesting clients (client ordering is lost)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnostics_for_requesting_client(dstates: Mapping[str, Sequence[DiagnosticsState]],\n",
    "                                          requesting_client: int\n",
    "                                         ) -> Mapping[str, DiagnosticsState]:\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        dstates: dict\n",
    "            key: data set selection strategy (e.g., 'global' or 'similar')\n",
    "            value: list of DiagnosticsState. Each DiagnosticsState\n",
    "                   corresponds to one requesting client.\n",
    "        requesting_client: int\n",
    "    \n",
    "    OUTPUTS:\n",
    "        res: dict\n",
    "            key: data set selection strategy (same keys as input `dstates`)\n",
    "            value: DiagnosticsState corresponding to client `requesting_client`.\n",
    "            \n",
    "    The DiagnosticsState.similarities and DiagnosticsState.epoch_counts are reordered,\n",
    "    to maintain the identity of each dataset. For example, the dataset\n",
    "    (, similarity, and epoch_count,) of client 1 are at index 1 irrespectively of\n",
    "    who the requesting client is. This is not the case in the raw training results.\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for key, dlist in diagnostics.items():\n",
    "        dstate = dlist[requesting_client]\n",
    "        similarities = np.array(dstate.similarities)\n",
    "        num_clients = similarities.shape[1]\n",
    "        \n",
    "        indexes_reordered = list(range(1, requesting_client+1)) + [0] + list(range(requesting_client+1, num_clients))\n",
    "        if requesting_client >= num_clients:\n",
    "            indexes_reordered = list(range(num_clients))\n",
    "        \n",
    "        similarities_reordered = np.array(dstate.similarities).T[indexes_reordered].T\n",
    "        epoch_counts_reordered = np.array(dstate.epoch_counts).T[indexes_reordered].T\n",
    "#         print(num_clients, indexes_reordered)\n",
    "#         print(similarities_reordered)\n",
    "        res[key] = dstate._replace(similarities=similarities_reordered,\n",
    "                                   epoch_counts=epoch_counts_reordered\n",
    "                                  )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individually per requesting client\n",
    "for requesting_client in range(3):\n",
    "    plot_test_accuracy_and_similarities(\n",
    "        get_diagnostics_for_requesting_client(diagnostics, requesting_client),\n",
    "        baseline_test_accuracies[requesting_client],\n",
    "        \"Requesting client: {}\".format(requesting_client)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EaE23XWAxE2x"
   },
   "source": [
    "# Questions\n",
    "\n",
    "1. Does the net.init also initialize the output layer based on batch size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Jax federated learning",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
